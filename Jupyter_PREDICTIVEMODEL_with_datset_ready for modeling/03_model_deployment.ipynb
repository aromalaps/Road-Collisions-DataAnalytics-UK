{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6138bf99-432b-4d3f-81ca-20ea82e1b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING SAVED MODEL\n",
      "============================================================\n",
      " Model loaded from: output/models\\xgboost_final.pkl\n",
      "\n",
      "=== MODEL METADATA ===\n",
      "model_type: XGBoost (sklearn Pipeline)\n",
      "training_date: 2026-01-10 05:40:25\n",
      "train_samples: 3768864\n",
      "val_samples: 754392\n",
      "test_samples: 1131072\n",
      "test_roc_auc: 0.732346820110733\n",
      "test_pr_auc: 0.14217710750714488\n",
      "threshold: 0.6363959908485413\n",
      "scale_pos_weight: 12.884601498662697\n",
      "\n",
      " Model ready for predictions\n",
      "\n",
      "Date range: 2010-01-01 00:00:00+00:00 to 2024-12-31 23:00:00+00:00\n",
      "Total years: 15.0\n",
      "\n",
      "=== NEW DATA LOADED ===\n",
      "Shape: (5654328, 25)\n",
      "\n",
      "=== GENERATING PREDICTIONS ===\n",
      "\n",
      "=== HIGH RISK HOURS (Top 5%) ===\n",
      "Threshold: 0.7356\n",
      "High-risk hours: 282,717\n",
      "\n",
      "Sample high-risk predictions:\n",
      "                collision_hour          region borough_name  temp  visibility  \\\n",
      "296  2010-01-13 08:00:00+00:00  greater london     Lewisham  -0.6         0.6   \n",
      "752  2010-02-01 08:00:00+00:00  greater london     Lewisham  -0.9        18.4   \n",
      "800  2010-02-03 08:00:00+00:00  greater london     Lewisham   1.0        10.1   \n",
      "824  2010-02-04 08:00:00+00:00  greater london     Lewisham   6.7         2.6   \n",
      "857  2010-02-05 17:00:00+00:00  greater london     Lewisham   7.1        19.7   \n",
      "968  2010-02-10 08:00:00+00:00  greater london     Lewisham   0.1        21.8   \n",
      "992  2010-02-11 08:00:00+00:00  greater london     Lewisham  -0.9        16.7   \n",
      "1088 2010-02-15 08:00:00+00:00  greater london     Lewisham  -0.6         5.6   \n",
      "1112 2010-02-16 08:00:00+00:00  greater london     Lewisham   3.0         5.2   \n",
      "1121 2010-02-16 17:00:00+00:00  greater london     Lewisham   4.2         8.5   \n",
      "\n",
      "      heavy_rain_flag  freezing_risk_flag  predicted_risk  \n",
      "296                 0                   1        0.745370  \n",
      "752                 0                   1        0.788950  \n",
      "800                 0                   1        0.739214  \n",
      "824                 0                   0        0.736786  \n",
      "857                 0                   0        0.740486  \n",
      "968                 0                   1        0.748202  \n",
      "992                 0                   1        0.751050  \n",
      "1088                0                   1        0.735720  \n",
      "1112                0                   0        0.760032  \n",
      "1121                0                   0        0.745602  \n",
      "\n",
      " Predictions saved to: output/tables/predictions_new_data.csv\n",
      "\n",
      "============================================================\n",
      "MODEL DEPLOYMENT COMPLETE \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NOTEBOOK 03: LOAD AND USE SAVED MODEL\n",
    "# ============================================================\n",
    "\n",
    "# Cell 1: Load Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Cell 2: Load Saved Model\n",
    "MODEL_DIR = r'output/models'\n",
    "model_filename = os.path.join(MODEL_DIR, 'xgboost_final.pkl')\n",
    "metadata_filename = os.path.join(MODEL_DIR, 'model_metadata.pkl')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING SAVED MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(f\" Model loaded from: {model_filename}\")\n",
    "\n",
    "# Load metadata\n",
    "metadata = joblib.load(metadata_filename)\n",
    "print(\"\\n=== MODEL METADATA ===\")\n",
    "for key, value in metadata.items():\n",
    "    if key != 'features':  # Skip long feature list\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n Model ready for predictions\")\n",
    "\n",
    "# Cell 3: Load New Data (Example)\n",
    "# If you want to make predictions on new data\n",
    "DATA_PATH = r\"FINAL_DATASET_FOR_TRAINING.csv\"\n",
    "df_new = pd.read_csv(DATA_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Parse datetime first\n",
    "df_new['collision_hour'] = pd.to_datetime(df_new['collision_hour'], utc=True, errors='coerce')\n",
    "\n",
    "# 2. Now you can perform calculations\n",
    "print(f\"\\nDate range: {df_new['collision_hour'].min()} to {df_new['collision_hour'].max()}\")\n",
    "\n",
    "total_days = (df_new['collision_hour'].max() - df_new['collision_hour'].min()).days\n",
    "print(f\"Total years: {total_days / 365.25:.1f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Parse datetime\n",
    "df_new['collision_hour'] = pd.to_datetime(df_new['collision_hour'], utc=True, errors='coerce')\n",
    "df_new['year'] = df_new['collision_hour'].dt.year\n",
    "df_new['month'] = df_new['collision_hour'].dt.month\n",
    "df_new['hour'] = df_new['collision_hour'].dt.hour\n",
    "df_new['dow'] = df_new['collision_hour'].dt.dayofweek\n",
    "\n",
    "print(\"\\n=== NEW DATA LOADED ===\")\n",
    "print(f\"Shape: {df_new.shape}\")\n",
    "\n",
    "# Cell 4: Make Predictions on New Data\n",
    "# Select features (must match training features)\n",
    "feature_cols = metadata['features']\n",
    "X_new = df_new[feature_cols]\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\n=== GENERATING PREDICTIONS ===\")\n",
    "predictions_proba = loaded_model.predict_proba(X_new)[:, 1]\n",
    "predictions_class = (predictions_proba >= metadata['threshold']).astype(int)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df_new['predicted_risk'] = predictions_proba\n",
    "df_new['predicted_collision'] = predictions_class\n",
    "\n",
    "\n",
    "# Cell 5: Example - Identify High-Risk Hours\n",
    "high_risk_threshold = df_new['predicted_risk'].quantile(0.95)\n",
    "high_risk_records = df_new[df_new['predicted_risk'] >= high_risk_threshold]\n",
    "\n",
    "print(\"\\n=== HIGH RISK HOURS (Top 5%) ===\")\n",
    "print(f\"Threshold: {high_risk_threshold:.4f}\")\n",
    "print(f\"High-risk hours: {len(high_risk_records):,}\")\n",
    "\n",
    "# Show sample high-risk hours\n",
    "print(\"\\nSample high-risk predictions:\")\n",
    "print(high_risk_records[['collision_hour', 'region', 'borough_name', \n",
    "                         'temp', 'visibility', 'heavy_rain_flag', \n",
    "                         'freezing_risk_flag', 'predicted_risk']].head(10))\n",
    "\n",
    "# Cell 6: Save Predictions (Optional)\n",
    "output_file = r'output/tables/predictions_new_data.csv'\n",
    "df_new[['collision_hour', 'region', 'borough_name', \n",
    "        'predicted_risk', 'predicted_collision']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n Predictions saved to: {output_file}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL DEPLOYMENT COMPLETE \")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc611c-483a-40d6-9c3d-650b6b566558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
